{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Handwritten Digits - Image Project\n",
        "- Tensorflow and Keras to create neural network\n",
        "  - takes input output and layers details like\n",
        "    - activcation fucntion\n",
        "    - loss fucntion\n",
        "    - accuracy metrics\n",
        "- Confusion matrix between predcited and test\n",
        "- plot using sns"
      ],
      "metadata": {
        "id": "zzJ3VuJ_i3eh"
      },
      "id": "zzJ3VuJ_i3eh"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "#It tells the notebook to display matplotlib plots directly below the code cells that produce them, rather than in a separate window.\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-ufdhgfNi7na"
      },
      "id": "-ufdhgfNi7na",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "ekH16FdAkBgR"
      },
      "id": "ekH16FdAkBgR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Databaset using Keras\n",
        "- Train and Split in Keras"
      ],
      "metadata": {
        "id": "F7BYfvKplv5b"
      },
      "id": "F7BYfvKplv5b"
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "THJm4jCkkRA_"
      },
      "id": "THJm4jCkkRA_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Each Image as 2D array of 28x28\n",
        "\n",
        "len(x_train)\n",
        "len(y_train)\n",
        "len(x_test)\n",
        "# X train and y_train are 2d arrays"
      ],
      "metadata": {
        "id": "YqR4ZzMvkl35"
      },
      "id": "YqR4ZzMvkl35",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST\n",
        "- Handwritten digits data in 2D form\n",
        "- 0 means black 255 means white"
      ],
      "metadata": {
        "id": "u430bXOckukr"
      },
      "id": "u430bXOckukr"
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train[0]))\n",
        "print(x_train[0])\n",
        "# This is 2D array"
      ],
      "metadata": {
        "id": "KBkqqsfQk18g"
      },
      "id": "KBkqqsfQk18g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### See Image using Matplot\n",
        "- plt.matshow(2D array)"
      ],
      "metadata": {
        "id": "dXyHJd_vlMOT"
      },
      "id": "dXyHJd_vlMOT"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(x_train[100])\n",
        "print(y_train[100])"
      ],
      "metadata": {
        "id": "_ecDtgXFlQUR"
      },
      "id": "_ecDtgXFlQUR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flatten 2D array 28X28 into 1D array"
      ],
      "metadata": {
        "id": "4auSI99-l1ZN"
      },
      "id": "4auSI99-l1ZN"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape\n",
        "# number of rows\n",
        "# each rows is 2d array"
      ],
      "metadata": {
        "id": "LRl59aQGl6rT"
      },
      "id": "LRl59aQGl6rT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Want (60000,784)\n",
        "x_train_flattened = x_train.reshape(len(x_train),28*28)\n",
        "x_test_flattened = x_test.reshape(len(x_test),28*28)\n",
        "x_train_flattened.shape"
      ],
      "metadata": {
        "id": "G8uE_FGTl53q"
      },
      "id": "G8uE_FGTl53q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flattened[0]\n",
        "print(len(x_train_flattened[0]))"
      ],
      "metadata": {
        "id": "n3vm7uMkmXJW"
      },
      "id": "n3vm7uMkmXJW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the x_train data between 0 to 1\n",
        "- Divide by 255"
      ],
      "metadata": {
        "id": "OBbKyyCEpoNF"
      },
      "id": "OBbKyyCEpoNF"
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_flattened = x_train_flattened/255"
      ],
      "metadata": {
        "id": "5f1ULrfJptF0"
      },
      "id": "5f1ULrfJptF0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras to Create Neural Network\n",
        "- want 784 as x1 x2 ... .x784 to connect with 10 ouputs 0 to 1\n",
        "- acitvation function = sigmoid\n",
        "- Then training using data yeh sab\n",
        "\n",
        "- Single layer input and output for now"
      ],
      "metadata": {
        "id": "c7QkkqnOnE7t"
      },
      "id": "c7QkkqnOnE7t"
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense(10): A fully connected layer with 10 neurons\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10,input_shape=(784,),activation='softmax')\n",
        "])\n",
        "\n",
        "# If dont want to flatten image tell its 28*28\n",
        "# Multiple layers hit and trial\n",
        "# model = keras.Sequential([\n",
        "      # keras.layers.Flatten(input_shape=(28,28))\n",
        "#     keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
        "#     keras.layers.Dense(10,activation='softmax')\n",
        "# ])\n",
        "\n",
        "\n",
        "# optimizer backward going to optain weight attain global minima\n",
        "# loss fucntion ouput and predicted difference used to attain weights\n",
        "# Gradient decent and cost function\n",
        "\n",
        "# metric when neural network compile goal is accuracy input output differtence\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "# epochs number of iteration the neural network going to train data\n",
        "model.fit(x_train_flattened,y_train,epochs=5)"
      ],
      "metadata": {
        "id": "gj94-wPHnNlx"
      },
      "id": "gj94-wPHnNlx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating | Predicition Keral Model on Test Dataset"
      ],
      "metadata": {
        "id": "s3rI94vup9Ex"
      },
      "id": "s3rI94vup9Ex"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test_flattened,y_test)"
      ],
      "metadata": {
        "id": "S_nEsCthqARu"
      },
      "id": "S_nEsCthqARu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(x_test[50])"
      ],
      "metadata": {
        "id": "02__G9G_qrrV"
      },
      "id": "02__G9G_qrrV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict= model.predict(x_test_flattened)\n",
        "print(y_predict[50])\n",
        "# This is 10 neurons output probability"
      ],
      "metadata": {
        "id": "D7x7ovHQrXty"
      },
      "id": "D7x7ovHQrXty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exact ouput based on 10 neurons\n",
        "# np.argmax returns the index of the max probability, i.e., the predicted class.\n",
        "print(np.argmax(y_predict[50]))"
      ],
      "metadata": {
        "id": "Co7wulzurnLG"
      },
      "id": "Co7wulzurnLG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0:5]"
      ],
      "metadata": {
        "id": "kpWS0X_wtEGz"
      },
      "id": "kpWS0X_wtEGz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert y_predicted into concrete class similar to y_test"
      ],
      "metadata": {
        "id": "mwHX7hH_tNsk"
      },
      "id": "mwHX7hH_tNsk"
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_labels = np.argmax(y_predict, axis=1)"
      ],
      "metadata": {
        "id": "4AmrvBjatVGS"
      },
      "id": "4AmrvBjatVGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_labels[0:5]"
      ],
      "metadata": {
        "id": "2v1sOa6ytWk0"
      },
      "id": "2v1sOa6ytWk0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Confusion Matrix"
      ],
      "metadata": {
        "id": "DT5ArGQes7Rv"
      },
      "id": "DT5ArGQes7Rv"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_predicted_labels)\n",
        "print(conf_matrix)\n",
        "\n",
        "# confusion_matrix = tf.math.confusion.matrix(labels=y_test, predictions=y_predicted_labels)\n",
        "# confusion_matrix"
      ],
      "metadata": {
        "id": "xa-FD69Ms-Q0"
      },
      "id": "xa-FD69Ms-Q0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize using seaborn"
      ],
      "metadata": {
        "id": "ij_jRKB2t2Bm"
      },
      "id": "ij_jRKB2t2Bm"
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "VIs7_8wwt4z9"
      },
      "id": "VIs7_8wwt4z9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=np.arange(10), yticklabels=np.arange(10))\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('MNIST Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WVZur1qZuJh_"
      },
      "id": "WVZur1qZuJh_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PKQFAFOYvT46"
      },
      "id": "PKQFAFOYvT46"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Functions\n",
        "- Use Sigmoid at output layer = [probability 0,1]\n",
        "- Between layers use tanh\n",
        "\n",
        "- Not sure of activation Use Relu max(0,x)\n",
        "- Leaky Relu max(01.x,x)"
      ],
      "metadata": {
        "id": "FRWn90lg-x26"
      },
      "id": "FRWn90lg-x26"
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "neNPjeFr_Ajf"
      },
      "id": "neNPjeFr_Ajf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sigmoid\n",
        "def sigmoid(x):\n",
        "  return 1/(1+math.exp(-x))"
      ],
      "metadata": {
        "id": "GQyZg7fs-xag"
      },
      "id": "GQyZg7fs-xag",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigmoid(-0)"
      ],
      "metadata": {
        "id": "ZR8ikMnD_HGg"
      },
      "id": "ZR8ikMnD_HGg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tanh\n",
        "def tanh(x):\n",
        "  return (math.exp(x)-math.exp(-x))/(math.exp(x)+math.exp(-x))"
      ],
      "metadata": {
        "id": "DyWzbfP4_I5W"
      },
      "id": "DyWzbfP4_I5W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tanh(100)"
      ],
      "metadata": {
        "id": "E6zWV6VH_VKh"
      },
      "id": "E6zWV6VH_VKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RELU\n",
        "def relu(x):\n",
        "  return max(0,x)\n",
        "def leaky_relu(x):\n",
        "  return max(0.1*x,x)"
      ],
      "metadata": {
        "id": "VEvHJrOp_W-I"
      },
      "id": "VEvHJrOp_W-I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu(0.5)\n",
        "leaky_relu(-0.5)"
      ],
      "metadata": {
        "id": "ixanqQEn_aZq"
      },
      "id": "ixanqQEn_aZq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent in Neural\n",
        "- Keras directly model leke train and fit\n",
        "- get weights and bias after epochs\n",
        "- Python simple implementation for x and y matrix to get weights"
      ],
      "metadata": {
        "id": "oanPGZ6X0x9n"
      },
      "id": "oanPGZ6X0x9n"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "vtQOfIdh063d"
      },
      "id": "vtQOfIdh063d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"insurance_data.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6JwCLWHT2Hn7"
      },
      "id": "6JwCLWHT2Hn7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df[['age','affordibility']]\n",
        "x.head()\n",
        "y= df['bought_insurance']\n",
        "y.head()\n",
        "x.shape"
      ],
      "metadata": {
        "id": "1xAyVnXX2I4H"
      },
      "id": "1xAyVnXX2I4H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Test and Scaling Data"
      ],
      "metadata": {
        "id": "T5LKOnTd2ZKF"
      },
      "id": "T5LKOnTd2ZKF"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, random_state=25)\n"
      ],
      "metadata": {
        "id": "ZOr0v6wl2XYe"
      },
      "id": "ZOr0v6wl2XYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaling Data Age / 100"
      ],
      "metadata": {
        "id": "T5pcCCtC2nOS"
      },
      "id": "T5pcCCtC2nOS"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train_scaled = X_train.copy()\n",
        "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
        "\n",
        "X_test_scaled = X_test.copy()\n",
        "X_test_scaled['age'] = X_test_scaled['age'] / 100"
      ],
      "metadata": {
        "id": "NTcrwM2V2e3N"
      },
      "id": "NTcrwM2V2e3N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled.head()"
      ],
      "metadata": {
        "id": "feS8dMx32jwL"
      },
      "id": "feS8dMx32jwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model-1 Keras and Tensorflow"
      ],
      "metadata": {
        "id": "kZIGsH_F2rOE"
      },
      "id": "kZIGsH_F2rOE"
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs to one output can use model from sklearn like logisitc but can be converted into\n",
        "# neurals if written in this way\n",
        "\n",
        "# Logistic Regression in Keras = Neural Network with:\n",
        "# 1 Dense layer\n",
        "\n",
        "# No hidden layers\n",
        "\n",
        "# Sigmoid activation (for binary classification)\n",
        "\n",
        "# Binary crossentropy loss\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
        "])\n",
        "\n",
        "# since logistic regression hai loss fucntion is log loss\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_scaled, y_train, epochs=500)"
      ],
      "metadata": {
        "id": "xVj-5sNq2ubP"
      },
      "id": "xVj-5sNq2ubP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate the model"
      ],
      "metadata": {
        "id": "Cg3m7PMb3yQZ"
      },
      "id": "Cg3m7PMb3yQZ"
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_scaled,y_test)"
      ],
      "metadata": {
        "id": "tyfGopKJ31Sb"
      },
      "id": "tyfGopKJ31Sb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "A9SAZx8y33MT"
      },
      "id": "A9SAZx8y33MT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_scaled"
      ],
      "metadata": {
        "id": "-BfefXEX37HE"
      },
      "id": "-BfefXEX37HE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "Uduloo1k4Gk8"
      },
      "id": "Uduloo1k4Gk8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coeff and Bias from the model which was trained\n",
        "- This means w1=5.060867, w2=1.4086502, bias =-2.9137027"
      ],
      "metadata": {
        "id": "55lII7064LAy"
      },
      "id": "55lII7064LAy"
    },
    {
      "cell_type": "code",
      "source": [
        "coef, intercept = model.get_weights()\n",
        "coef, intercept"
      ],
      "metadata": {
        "id": "Kc2aWP_k4OTK"
      },
      "id": "Kc2aWP_k4OTK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model-2 Using Python Done in Siddharsan Video\n",
        "- Loss function know\n",
        "- x y w1 w2 b and gradiet descent is know\n",
        "- learning rate and number of iteration known"
      ],
      "metadata": {
        "id": "3EMoc4FK4UlB"
      },
      "id": "3EMoc4FK4UlB"
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_numpy(X):\n",
        "   return 1/(1+np.exp(-X))\n",
        "\n",
        "sigmoid_numpy(np.array([12,0,1]))"
      ],
      "metadata": {
        "id": "1pBwfTfJ4ekF"
      },
      "id": "1pBwfTfJ4ekF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_predicted):\n",
        "    epsilon = 1e-15\n",
        "    y_predicted_new = [max(i,epsilon) for i in y_predicted]\n",
        "    y_predicted_new = [min(i,1-epsilon) for i in y_predicted_new]\n",
        "    y_predicted_new = np.array(y_predicted_new)\n",
        "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-y_predicted_new))"
      ],
      "metadata": {
        "id": "ntTMVSqx5Mtf"
      },
      "id": "ntTMVSqx5Mtf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(age, affordability, y_true, epochs, loss_thresold):\n",
        "    w1 = w2 = 1\n",
        "    bias = 0\n",
        "    rate = 0.5 #Learning rate fix\n",
        "    n = len(age)\n",
        "    for i in range(epochs):\n",
        "        weighted_sum = w1 * age + w2 * affordability + bias\n",
        "        y_predicted = sigmoid_numpy(weighted_sum)\n",
        "        loss = log_loss(y_true, y_predicted)\n",
        "\n",
        "        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted-y_true))\n",
        "        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted-y_true))\n",
        "\n",
        "        bias_d = np.mean(y_predicted-y_true)\n",
        "        w1 = w1 - rate * w1d\n",
        "        w2 = w2 - rate * w2d\n",
        "        bias = bias - rate * bias_d\n",
        "\n",
        "        print (f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
        "\n",
        "        if loss<=loss_thresold:\n",
        "            break\n",
        "\n",
        "    return w1, w2, bias"
      ],
      "metadata": {
        "id": "9c3YiUK25XuG"
      },
      "id": "9c3YiUK25XuG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_descent(X_train_scaled['age'],X_train_scaled['affordibility'],y_train,500, 0.4631)"
      ],
      "metadata": {
        "id": "UdpONgyB5h2B"
      },
      "id": "UdpONgyB5h2B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coef, intercept"
      ],
      "metadata": {
        "id": "hblwdfW552MY"
      },
      "id": "hblwdfW552MY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}